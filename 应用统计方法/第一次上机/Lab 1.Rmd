---
title: 'Tutorial 5: Regression Lab 1'
header-includes: \usepackage{ctex}
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---
# 一个书上的例子
## 1.数据准备
```{r}
y <- c(1278.89, 1453.8, 1671.7, 2110.8, 2851.3, 3537.57, 3919.5, 4185.6, 4331.6, 4615.9, 4998, 5309.01, 6029.92, 6510.94, 7182.1, 7942.88, 8696.55, 9997.47, 11242.85, 12264.55, 13471.45, 15160.89, 16674.32)
x <- c(1510.16, 1700.6, 2026.6, 2577.4, 3496.2, 4282.95, 4838.9, 5160.3, 5425.1, 5854, 6279.98, 6859.6, 7702.8, 8472.2, 9421.6, 10493, 11759.5, 13785.8, 15780.76, 17174.65, 19109.4, 21809.8, 24564.7)
#y<-scale(y)
#x<-scale(x)
```

## 2.基本绘图
```{r}
plot(x,y)
#plot(x,y, xlab = "给x轴标签",ylab = "给y轴标签")
plot(x,y, xlim=c(0,25000),ylim=c(0,17000))
plot(x,y, xlim=c(0,25000),ylim=c(0,17000),pch=19,col="red") 
#pch:点的类型
#col:ָ点的颜色
#bg:填充色
#lty:线型 1-6
```

##3.数据探索
```{r}
#描述性统计表
summary(x)
sd(x)
length(x)
sort(x)
which(x>=1500)

#相关性分析
cor(x,y)
```

##4.线性回归拟合
```{r}
#最小二乘法的拟合结果
myfit <- lm(y~x)
coefficients(myfit) 
confint(myfit)
fitted(myfit)
residuals(myfit)#残差
anova(myfit)#方差分析
summary(myfit)
```

##5.残差分析
正态性： 当预测变量值固定时，因变量成正态分布，则残差值（预测与真实的差值）也应该是一个均值为0的正态分布。“正态Q-Q图”（Normal Q-Q，右上）是在正态分布对应的值下，标准化残差的概图。若满足正态假设，那么图上的点应该落在呈45度角的直线上；若不是如此，那么 就违反了正态性的假设。

独立性： 你无法从这些图中分辨出因变量值是否相互独立，只能从收集的数据中来验证。比如，没有任何先验的理由去相信一位女性的体重会影响另外一位女性的体重。假若你发现数据是从一个家庭抽样得来的，那么可能必须要调整模型独立性的假设。

线性： 若因变量与自变量线性相关，那么残差值与预测（拟合）值就没有任何系统关联。换句话说，除了白噪声，模型应该包含数据中所有的系统方差。在“残差图与拟合图” （Residuals vs Fitted，左上）中可以清楚地看到一个曲线关系，这暗示着你可能需要对回 归模型加上一个二次项。

同方差性： 若满足不变方差假设，那么在“位置尺度图”（Scale-Location Graph，左下） 中，水平线周围的点应该随机分布。

最后一幅“残差与杠杆图”（Residuals vs Leverage）提供了你可能关注的单个观测点的信息。从图形可以鉴别出离群点、高杠杆值点和强影响点。下面来详细介绍。

一个观测点是离群点，表明拟合回归模型对其预测效果不佳（产生了巨大的或正或负的残差）

一个观测点有很高的杠杆值，表明它是一个异常的预测变量值的组合
。
也就是说，在预测变量空间中，它是一个离群点。因变量值不参与计算一个观测点的杠杆值。

一个观测点是强影响点（influential observation），表明它对模型参数的估计产生的影响过大，非常不成比例。强影响点可以通过Cook距离即Cook‘s D统计量来鉴别。

```{r}
plot(myfit)
```

## 6.预测
```{r}
library(forecast)
plot(forecast(myfit,3))
plot(forecast(myfit,24666),xlim=c(0,25000),ylim=c(0,17000))
predict(myfit)
predict(myfit,newdata=data.frame(x=c(400,500,600)))
```

## 7.练习

### 7.1 向量基本操作
现有10个人的期末考试成绩为：100, 65, 80, 79, 88, 95, 93, 35, 56, 68

1. 创建向量x来存储上述数据；

```{r}
x <- c(100, 65, 80, 79, 88, 95, 93, 35, 56, 68)

```

2. 将x从小到大排序，并分别找出最大值，最小值、中位数和第三大的元素；

```{r}
x1 <- sort(x, decreasing = FALSE)
print(x1)
print(c(max(x1), min(x1), median(x1), x1[length(x1)-3+1]))

```

3. 计算平均值、标准差和方差；

```{r}
meanx <- mean(x)
stdx <- sd(x)
varx <- var(x)
print(c(meanx, stdx, varx))

```

4. 计算及格的人数；

```{r}
pass <- x[x>=60]
cnt <- length(pass)
print(cnt)

```



### 7.2 冬奥会
现在有中国1992～2018年在冬奥会上的奖牌统计数据WinterOlym

1. 创建一个变量medal来存储上述数据；
```{r}
medal <-  read.csv("WinterOlym.csv", header = TRUE)

```

2. 应用一元回归方法预测2022冬奥会中国总奖牌数目；
```{r}
t <- medal[,c(1,5)]
olst <- lm(Total~Time, data=t)
predictt <- predict(olst, newdata = data.frame(Time = 2022), interval = "confidence")
print(predictt)

```

3. 应用一元回归方法分别预测2022冬奥会中国金银铜牌数目；
```{r}
olsg <- lm(Gold~Time, data=medal)
olss <- lm(Silver~Time, data=medal)
olsb <- lm(Bronze~Time, data=medal)
predictg <- predict(olsg, newdata = data.frame(Time = 2022))
predicts <- predict(olss, newdata = data.frame(Time = 2022))
predictb <- predict(olsb, newdata = data.frame(Time = 2022))
print(c(predictg, predicts, predictb))

```

4. 结合中国实际获得的奖牌情况，对比分析2和3的预测结果；
```{r}
print(predictt - (predictg+ predicts+ predictb))
```
发现中国其实拿了15块奖牌，与预测的12~13块差别不大；
但金牌9块与预测的3.6差别极大，考虑到只是做了线性回归，而获奖情况不只是往年的成绩就能预测，由此才会产生这种可以理解的差别。

5. 从高斯马尔可夫条件出发，分析2中创建的模型好坏。

很难说明往年的奖牌总数数据的误差是零均值，同方差且不相关的。因此建立线性回归模型的前提并不能很好满足，故模型的预测很可能不准确。


## 8.参考
R语言统计-回归篇：回归诊断 https://zhuanlan.zhihu.com/p/341318994
R语言数据分析: 线性回归 https://zhuanlan.zhihu.com/p/378228742